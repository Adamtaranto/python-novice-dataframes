{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: rgb(255,165,0); border: solid 1px rgb(129,199,132); padding: 10px;\"> \n",
    "    \n",
    "<h1>Data Analysis with Pandas</h1>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas` module provides high-performance, easy-to-use data structures and data analysis tools. The main data structure is the `DataFrame`, which you can think of as an in-memory 2D table (like a spreadsheet, with column names and row labels). Many features from Excel are available programmatically, such as creating pivot tables, computing columns based on other columns, plotting graphs, etc. You can also group rows by column value, or join tables much like in SQL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "**Section 1: Series and Dataframes**  \n",
    "\n",
    "**[Series](#Series)**\n",
    " - [Creating a Series](#Creating-a-Series)\n",
    " - [Selecting and filtering in Series](#Selecting-and-filtering-in-Series)\n",
    " - [Operations on Series](#Operations-on-Series)\n",
    " - [Plotting a Series](#Plotting-a-Series)\n",
    "\n",
    "**[DataFrames](#DataFrames)**\n",
    " - [Creating a DataFrame](#Creating-a-DataFrame)\n",
    " - [Selecting and filtering in DataFrames](#Selecting-and-Filtering-in-DataFrames)\n",
    " - [Transposing](#Transposing)\n",
    " - [Methods](#Methods)\n",
    " - [Adding and removing columns](#Adding-and-removing-columns)\n",
    " - [Assigning new columns](#Assigning-new-columns)\n",
    " - [Evaluating an expression](#Evaluating-an-expression)\n",
    " - [Querying a DataFrame](#Querying-a-DataFrame)\n",
    " - [Sorting a DataFrame](#Sorting-a-DataFrame)\n",
    " - [Operations on DataFrame](#Operations-on-DataFrame)\n",
    " - [Automatic alignment for DataFrames](#Automatic-alignment-for-DataFrames)\n",
    " - [Plotting a DataFrame](#Plotting-a-DataFrame)\n",
    " - [Combining DataFrames](#Combining-DataFrames)\n",
    " - [SQL like joins](#SQL-like-joins)\n",
    " - [Concatenation](#Concatenation)\n",
    "\n",
    "**Section 2: Working with real Data**\n",
    "\n",
    " - [Loading data from CSV](#Loading-data-from-CSV)\n",
    " - [Handling missing data](#Handling-missing-data)\n",
    " - [Exploring your data](#Exploring-your-data)\n",
    " - [Overview functions](#Overview-functions)\n",
    " - [Aggregating with groupby](#Aggregating-with-groupby)\n",
    " - [Saving](#Saving-to-files)\n",
    " - [Plotting Data](#Plotting-data)\n",
    " \n",
    "[Exercises](#Exercises)\n",
    " - [Possible solutions](#Possible-solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: rgb(255,165,0); border: solid 1px rgb(129,199,132); padding: 10px;\">    \n",
    "\n",
    "<h2>Setup</h2>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First set this so that jupyter notebook prints all output from a cell, \n",
    "# not just the last command\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Let's also suppress warnings, as they can get annoying sometimes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing Packages</h3>\n",
    "\n",
    "Let's import `pandas` with the usual convention as `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will import some additional python packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(27,94,32); background: rgb(200,230,201); border: solid 1px rgb(129,199,132); padding: 10px;\">\n",
    "\n",
    "<h3>Challange 1:</h3>\n",
    "\n",
    "**Did you see a \"ModuleNotFoundError\"?**\n",
    "\n",
    "Packages must be installed in the same environment where you are running this notebook before you can import them.\n",
    "\n",
    "You can install packages using `conda` or `pip`\n",
    "\n",
    "```bash\n",
    "# Option 1: Using conda\n",
    "conda install -c conda-forge packagenamehere\n",
    "\n",
    "# Option 2: Using the default python package installer\n",
    "pip install packagenamehere\n",
    "```  \n",
    "\n",
    "These commands need to run in the bash shell, to run bash comands from a Jupyter notebook you can add a `!` to the begining of the command.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's call the bash shell to install a missing package\n",
    "# Uncomment lines to run them.\n",
    "#!pip install packagenamehere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Checking your Path</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the current working directory for this notebook using the 'os' module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get working dir\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next make sure you are in the `python-novice-dataframes/workshop` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you are in \"python-novice-dataframes\" you can navigate\n",
    "# into the \"workshop\" dir with this command.\n",
    "#os.chdir(\"./workshop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: rgb(255,165,0); border: solid 1px rgb(129,199,132); padding: 10px;\">    \n",
    "\n",
    "<h2>Series</h2>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Series` is a one-dimensional array-like object containing a sequence of values and an associated array of row labels, called its *index*.\n",
    "\n",
    "You can recognize that your object is a Series because there will be has two attributes printed out at the bottom: the Name (if indeed there is a name) and dtype (type)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Creating a Series</h2>\n",
    "\n",
    "</div>\n",
    "The simplest `Series` is formed from only an array of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series([2,-1,3,5])\n",
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string representation of a `Series` displayed interactively shows the index on the\n",
    "left and the values on the right.\n",
    "You can get the array representation and index object of the `Series` via\n",
    "its values and index attributes, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.index # Like range(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(obj.index) # if you want the index as a list of values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to create a `Series` with an index identifying each data point with a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj2 = pd.Series([2,-1,3,5], index=['a', 'b', 'c', 'd'])\n",
    "obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(obj2.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Series` can have a `name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_withName = pd.Series([83, 68], index=[\"bob\", \"alice\"], name=\"weights\")\n",
    "obj_withName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create a `Series` object from a `dict`. The keys will be used as index labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weightdata = {\"john\": 86, \"michael\": 68, \"alice\": 68, \"bob\": 83}\n",
    "obj3 = pd.Series(weightdata)\n",
    "obj3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Selecting and filtering in Series</h2>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared with `NumPy` arrays, you can use labels in the index when selecting single values or a set of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2[['b','c','d']] \n",
    "# Here ['b', 'c', 'd'] is interpreted as a list of indices, even though it contains strings instead of integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can still access the items by integer location, like in a regular array. By default, the rank of the item in the `Series` starts at **0**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2[[1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2[obj2 < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing with labels behaves differently than normal Python slicing in that the endpoint is inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2['b':'c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it clear when you are accessing by label or by integer location, it is recommended to always use the `loc` attribute when accessing by label, and the `iloc` attribute when accessing by integer location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.loc[\"a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing a `Series` also slices the index labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2.iloc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can lead to unexpected results when using the default numeric labels, so be careful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise = pd.Series([1000, 1001, 1002, 1003])\n",
    "surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise_slice = surprise[2:]\n",
    "surprise_slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh look! The first element has index label **2**. The element with index label 0 is absent from the slice.\n",
    "\n",
    "But remember that you can access elements by integer location using the iloc attribute. This illustrates another reason why it's always better to use loc and iloc to access Series objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise_slice.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Operations on Series</h2>\n",
    "\n",
    "</div>\n",
    "\n",
    "`Series` objects behave much like a one-dimensional `ndarray`, and you can often pass them as parameters to `NumPy` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We have already imported the numpy library as \"np\"\n",
    "#import numpy as np\n",
    "np.exp(obj2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arithmetic operations on `Series` are also possible, and they apply *elementwise*, just like for `ndarray`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2 + [1000,2000,3000,4000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to `NumPy`, if you add a single number to a `Series`, that number is added to all items in the `Series`. This is called *broadcasting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj2 + 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same is true for all binary operations and even conditional operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Plotting a Series</h2>\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "`pandas` makes it easy to plot `Series` data using `matplotlib`. Just import `matplotlib` and call the `plot()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"ggplot\")\n",
    "###\n",
    "temperatures = [4.4,5.1,6.1,6.2,6.1,6.1,5.7,5.2,4.7,4.1,3.9,3.5]\n",
    "s7 = pd.Series(temperatures, name=\"Temperature\")\n",
    "s7.plot()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: rgb(255,165,0); border: solid 1px rgb(129,199,132); padding: 10px;\">    \n",
    "\n",
    "<h1>DataFrames</h1>\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataFrame` represents a rectangular table of data and contains an ordered collection of columns, each of which can be a different value type (numeric, string, boolean, etc.). You can see `DataFrame`s as `dict` of `Series`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Creating a DataFrame</h2>\n",
    "\n",
    "</div>\n",
    "\n",
    "<h3>Building DataFrames from Dictionaries</h3>\n",
    "\n",
    "There are many ways to construct a `DataFrame`, though one of the most common is from a `dict` of equal-length lists or `Numpy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'],\n",
    "'year': [2000, 2001, 2002, 2001, 2002, 2003],\n",
    "'pop': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A python `dict` consists of `key:value` pairs. \n",
    "Let's inspect our dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now we will convert the dict into a pandas dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we can see that the dictionary keys have been converted to column names. \n",
    "\n",
    "We can access and edit these using the `.columns` attribute for our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(27,94,32); background: rgb(200,230,201); border: solid 1px rgb(129,199,132); padding: 10px;\">\n",
    "\n",
    "<h3>Challange 2:</h3>\n",
    "\n",
    "Pass a list of strings to `df.columns` to changes the names.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your solution here!\n",
    "\n",
    "# View the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Other ways to create a DataFrame</h3>\n",
    "\n",
    "You can also create a `DataFrame` by passing a `dict` of `Series` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "people_dict = {\n",
    "    \"weight\": pd.Series([68, 83, 112], index=[\"alice\", \"bob\", \"charles\"]),\n",
    "    \"birthyear\": pd.Series([1984, 1985, 1992], index=[\"bob\", \"alice\", \"charles\"], name=\"year\"),\n",
    "    \"children\": pd.Series([0, 3], index=[\"charles\", \"bob\"]),\n",
    "    \"hobby\": pd.Series([\"Biking\", \"Dancing\"], index=[\"alice\", \"bob\"]),\n",
    "}\n",
    "people = pd.DataFrame(people_dict)\n",
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note:\n",
    "* The `Series` were automatically aligned based on their index.\n",
    "* Missing values are represented as `NaN`.\n",
    "* `Series` names are ignored (the name `\"year\"` was dropped)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass a list of columns and/or index row labels to the `DataFrame` constructor, it will guarantee that these columns and/or rows will exist, in that order, and no other column/row will exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(\n",
    "        people_dict,\n",
    "        columns=[\"birthyear\", \"weight\", \"height\"],\n",
    "        index=[\"bob\", \"alice\", \"eugene\"]\n",
    "     )\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another convenient way to create a `DataFrame` is to pass all the values to the constructor as an `ndarray`, or a list of lists, and specify the column names and row index labels separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [\n",
    "            [1985, np.nan, \"Biking\",   68],\n",
    "            [1984, 3,      \"Dancing\",  83],\n",
    "            [1992, 0,      np.nan,    112]\n",
    "         ]\n",
    "df3 = pd.DataFrame(\n",
    "        values,\n",
    "        columns=[\"birthyear\", \"children\", \"hobby\", \"weight\"],\n",
    "        index=[\"alice\", \"bob\", \"charles\"]\n",
    "     )\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(27,94,32); background: rgb(200,230,201); border: solid 1px rgb(129,199,132); padding: 10px;\">\n",
    "\n",
    "<h3>Challenge:</h3>\n",
    "\n",
    "Create the following DataFrame (But use `name` as the index):\n",
    "\n",
    "| name | age | state | num_children | num_pets |\n",
    "|----|---|----|---|----|\n",
    "| john  | 23 | iowa | 2 | 0 |\n",
    "| mary  | 78 | dc | 2 | 4 |\n",
    "| peter  | 22 | california | 0 | 0 |\n",
    "| jeff  | 19 | texas | 1 | 5 |\n",
    "| bill  | 45 | washington | 2 | 0 |\n",
    "| lisa  | 33 | dc | 1 | 0 |\n",
    "\n",
    "Dataframe should be called `employees_df`\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Selecting and Filtering in DataFrames</h2>\n",
    "\n",
    "</div>\n",
    "\n",
    "Let's go back to the `people` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the row and column names using the `.index` and `.columns` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Column labels\n",
    "people.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Row labels\n",
    "people.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Accessing Columns</h3>\n",
    "\n",
    "You can access columns pretty much as you would expect. They are returned as `Series` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people[\"birthyear\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get multiple columns at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people[[\"birthyear\", \"hobby\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Accessing rows with loc and iloc</h3>\n",
    "\n",
    "The `loc` attribute lets you access rows instead of columns. The result is a `Series` object in which the `DataFrame`'s column names are mapped to row index labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "people.loc[\"charles\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also access rows by integer location using the `iloc` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get a slice of rows, and this returns a `DataFrame` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.iloc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Filtering</h3>\n",
    "\n",
    "Pandas Series objects act like vectors in R in that you can ask logical questions of them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass a boolean array to get the matching rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people[np.array([True, False, True])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is most useful when combined with boolean expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "people[people[\"birthyear\"] < 1990]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Don’t forget to .copy()</h2>\n",
    "\n",
    "</div>\n",
    "\n",
    "This is because in python when you define a new object to be an existing object (`pandas_df_new = pandas_df`), you are actually creating a new “pointer” to the same underlying object being pointed to by the original name `pandas_df`. `pandas_df_new` becomes like an “alias” for `pandas_df`, rather than an entirely new object.\n",
    "\n",
    "To avoid this issue, when defining a new DataFrame based on an existing DataFrame, you need to explicitly create a new object using the `copy()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# redefine the original pandas DataFrame:\n",
    "pandas_df = pd.DataFrame({'a': [1,2,3,4], \n",
    "                          'b': [5,6,7,8]})\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pandas_df_new as a \"copy\" of pandas_df:\n",
    "pandas_df_new = pandas_df.copy()\n",
    "pandas_df_new['c'] = [9,10,11,12]\n",
    "pandas_df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that pandas_df did not change this time\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Transposing</h2>\n",
    "\n",
    "</div>\n",
    "\n",
    "You can swap columns and indices using the `T` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "people.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Methods</h2>\n",
    "\n",
    "</div>\n",
    "\n",
    "Extracting attributes is not the only use of the object.xyz dot syntax. Similar syntax also lets you apply object-specific functions to the object using the object.fun() dot syntax.\n",
    "\n",
    "For example, we can apply the mean() and sum() DataFrame methods to a DataFrame object to compute the mean and sum of each column in the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_df = pd.DataFrame({'a': [1,2,3,4], \n",
    "                       'b': [5,6,7,8]})\n",
    "\n",
    "num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Calculate the mean per column\n",
    "num_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try calling the `.mean()` method on the `people` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#people.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Adding and removing columns</h2>\n",
    "\n",
    "</div>\n",
    "\n",
    "You can generally treat `DataFrame` objects like dictionaries of `Series`, so the following work fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people[\"age\"] = 2024 - people[\"birthyear\"]  # adds a new column \"age\"\n",
    "people[\"over 30\"] = people[\"age\"] > 30      # adds another column \"over 30\"\n",
    "birthyears = people.pop(\"birthyear\")\n",
    "del people[\"children\"]\n",
    "\n",
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birthyears"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you add a new colum, it must have the same number of rows. Missing rows are filled with NaN, and extra rows are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people[\"pets\"] = pd.Series({\"bob\": 0, \"charles\": 5, \"eugene\":1})  # alice is missing, eugene is ignored\n",
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When adding a new column, it is added at the end (on the right) by default. You can also insert a column anywhere else using the `insert()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "people.insert(1, \"height\", [172, 181, 185])\n",
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Assigning new columns</h2>\n",
    "\n",
    "</div>\n",
    "\n",
    "You can also create new columns by calling the `assign()` method. Note that this returns a new `DataFrame` object, the original is not modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.assign(\n",
    "    body_mass_index = people[\"weight\"] / (people[\"height\"] / 100) ** 2,\n",
    "    has_pets = people[\"pets\"] > 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you cannot access columns created within the same assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    people.assign(\n",
    "        body_mass_index = people[\"weight\"] / (people[\"height\"] / 100) ** 2,\n",
    "        overweight = people[\"body_mass_index\"] > 25\n",
    "    )\n",
    "except KeyError as e:\n",
    "    print(\"Key error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution is to split this assignment in two consecutive assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = people.assign(body_mass_index = people[\"weight\"] / (people[\"height\"] / 100) ** 2)\n",
    "df5.assign(overweight = df5[\"body_mass_index\"] > 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having to create a temporary variable **df5** is not very convenient. You may want to just chain the assigment calls, but it does not work because the `people` object is not actually modified by the first assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    (people\n",
    "         .assign(body_mass_index = people[\"weight\"] / (people[\"height\"] / 100) ** 2)\n",
    "         .assign(overweight = people[\"body_mass_index\"] > 25)\n",
    "    )\n",
    "except KeyError as e:\n",
    "    print(\"Key error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But fear not, there is a simple solution. You can pass a function to the `assign()` method (typically a `lambda` function), and this function will be called with the `DataFrame` as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(people\n",
    "     .assign(body_mass_index = lambda df: df[\"weight\"] / (df[\"height\"] / 100) ** 2)\n",
    "     .assign(overweight = lambda df: df[\"body_mass_index\"] > 25)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem solved!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Evaluating an expression</h2>\n",
    "\n",
    "</div>\n",
    "\n",
    "A great feature supported by `pandas` is expression evaluation. This relies on the `numexpr` library which must be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "people.eval(\"weight / (height/100) ** 2 > 25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment expressions are also supported. Let's set `inplace=True` to directly modify the `DataFrame` rather than getting a modified copy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First let's remind ourselves what columns we have\n",
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now evaluate an expression and assign it to a new column called \"body_mass_index\"\n",
    "people.eval(\"body_mass_index = weight / (height/100) ** 2\", inplace=True)\n",
    "\n",
    "#View the dataframe\n",
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use a local or global variable in an expression by prefixing it with `'@'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overweight_threshold = 30\n",
    "people.eval(\"overweight = body_mass_index > @overweight_threshold\", inplace=True)\n",
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Querying a DataFrame</h2>\n",
    "\n",
    "</div>\n",
    "\n",
    "The `query()` method lets you filter a `DataFrame` based on a query expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.query(\"age > 30 and pets == 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(27,94,32); background: rgb(200,230,201); border: solid 1px rgb(129,199,132); padding: 10px;\">\n",
    "\n",
    "<h3>Challenge:</h3>\n",
    "\n",
    "Create a Series using the following number: `3.14`, `2.718`, `1.618` with the following labels \"`pi`\", \"`euler's number`\", \"`golden ratio`\". Then filter values that are only greater than 2.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Sorting a DataFrame</h2>\n",
    "\n",
    "</div>\n",
    "\n",
    "You can sort a `DataFrame` by calling its `sort_index` method. By default it sorts the rows by their index label, in ascending order, but let's reverse the order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `sort_index` returned a sorted *copy* of the `DataFrame`. To modify `people` directly, we can set the `inplace` argument to `True`. Also, we can sort the columns instead of the rows by setting `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.sort_index(axis=1, inplace=True)\n",
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sort the `DataFrame` by the values instead of the labels, we can use `sort_values` and specify the column to sort by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.sort_values(by=\"age\", inplace=True)\n",
    "people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Operations on DataFrame</h2>\n",
    "\n",
    "</div> \n",
    "\n",
    "Although `DataFrame`s do not try to mimick `NumPy` arrays, there are a few similarities. Let's create a `DataFrame` to demonstrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_array = np.array([[8,8,9],[10,9,9],[4, 8, 2], [9, 10, 10]])\n",
    "grades = pd.DataFrame(grades_array, columns=[\"sep\", \"oct\", \"nov\"], index=[\"alice\",\"bob\",\"charles\",\"darwin\"])\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can apply `NumPy` mathematical functions on a `DataFrame`. The function is applied to all values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, adding a single value to a `DataFrame` will add that value to all elements in the `DataFrame`. This is called *broadcasting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the same is true for all other binary operations, including arithmetic (`*`,`/`,`**`...) and conditional (`>`, `==`...) operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades >= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation operations, such as computing the `max`, the `sum` or the `mean` of a `DataFrame`, apply to each column, and you get back a `Series` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `all` method is also an aggregation operation: it checks whether all values are `True` or not. Let's see during which months all students got a grade greater than `5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(grades > 5).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of these functions take an optional `axis` parameter which lets you specify along which axis of the `DataFrame` you want the operation executed. The default is `axis=0`, meaning that the operation is executed vertically (on each column). You can set `axis=1` to execute the operation horizontally (on each row). For example, let's find out which students had all grades greater than `5`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(grades > 5).all(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `any` method returns `True` if any value is True. Let's see who got at least one grade 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(grades == 10).any(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you add a `Series` object to a `DataFrame` (or execute any other binary operation), `pandas` attempts to broadcast the operation to all *rows* in the `DataFrame`. This only works if the `Series` has the same size as the `DataFrame`s rows. For example, let's substract the `mean` of the `DataFrame` (a `Series` object) from the `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades - grades.mean()  # equivalent to: grades - [7.75, 8.75, 7.50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We substracted `7.75` from all September grades, `8.75` from October grades and `7.50` from November grades. It is equivalent to substracting this `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([[7.75, 8.75, 7.50]]*4, index=grades.index, columns=grades.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to substract the global mean from every grade, here is one way to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "grades - grades.values.mean() # substracts the global mean (8.00) from all grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Automatic alignment for DataFrames</h2>\n",
    "\n",
    "</div>\n",
    "Similar to `Series`, when operating on multiple `DataFrame`s, `pandas` automatically aligns them by row index label, but also by column names. Let's create a `DataFrame` with bonus points for each person from October to December:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonus_array = np.array([[0,np.nan,2],[np.nan,1,0],[0, 1, 0], [3, 3, 0]])\n",
    "bonus_points = pd.DataFrame(bonus_array, columns=[\"oct\", \"nov\", \"dec\"], index=[\"bob\",\"colin\", \"darwin\", \"charles\"])\n",
    "bonus_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades + bonus_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the addition worked in some cases but way too many elements are now empty. That's because when aligning the `DataFrame`s, some columns and rows were only present on one side, and thus they were considered missing on the other side (`NaN`). Then adding `NaN` to a number results in `NaN`, hence the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Handling missing data</h2>\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "Dealing with missing data is a frequent task when working with real life data. `pandas` offers a few tools to handle missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `isnull` and `notnull` functions in `pandas` can be used to detect missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.notnull(grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want that, for instance, missing data should result in a zero, instead of `NaN`. We can replace all `NaN` values by a any value using the `fillna()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(grades + bonus_points).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a bit unfair that we're setting grades to zero in September, though. Perhaps we should decide that missing grades are missing grades, but missing bonus points should be replaced by zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_bonus_points = bonus_points.fillna(0)\n",
    "fixed_bonus_points.insert(0, \"sep\", 0)\n",
    "fixed_bonus_points.loc[\"alice\"] = 0\n",
    "grades + fixed_bonus_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's much better: although we made up some data, we have not been too unfair.\n",
    "\n",
    "Another way to handle missing data is to interpolate. Let's look at the `bonus_points` `DataFrame` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonus_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's call the `interpolate` method. By default, it interpolates vertically (`axis=0`), so let's tell it to interpolate horizontally (`axis=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonus_points.interpolate(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bob had 0 bonus points in October, and 2 in December. When we interpolate for November, we get the mean: 1 bonus point. Colin had 1 bonus point in November, but we do not know how many bonus points he had in September, so we cannot interpolate, this is why there is still a missing value in October after interpolation. To fix this, we can set the September bonus points to 0 before interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_bonus_points = bonus_points.copy()\n",
    "better_bonus_points.insert(0, \"sep\", 0)\n",
    "better_bonus_points.loc[\"alice\"] = 0\n",
    "better_bonus_points = better_bonus_points.interpolate(axis=1)\n",
    "better_bonus_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we have reasonable bonus points everywhere. Let's find out the final grades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades + better_bonus_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is slightly annoying that the September column ends up on the right. This is because the `DataFrame`s we are adding do not have the exact same columns (the `grades` `DataFrame` is missing the `\"dec\"` column), so to make things predictable, `pandas` orders the final columns alphabetically. To fix this, we can simply add the missing column before adding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grades[\"dec\"] = np.nan\n",
    "final_grades = grades + better_bonus_points\n",
    "final_grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's not much we can do about December and Colin: it's bad enough that we are making up bonus points, but we can't reasonably make up grades (well I guess some teachers probably do). So let's call the `dropna()` method to get rid of rows that are full of `NaN`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_grades_clean = final_grades.dropna(how=\"all\")\n",
    "final_grades_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's remove columns that are full of `NaN`s by setting the `axis` argument to `1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_grades_clean = final_grades_clean.dropna(axis=1, how=\"all\")\n",
    "final_grades_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Aggregating with `groupby`</h2>\n",
    "\n",
    "</div>\n",
    "Similar to the SQL language, `pandas` allows grouping your data into groups to run calculations over each group.\n",
    "\n",
    "First, let's add some extra data about each person so we can group them, and let's go back to the `final_grades` `DataFrame` so we can see how `NaN` values are handled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_grades[\"hobby\"] = [\"Biking\", \"Dancing\", np.nan, \"Dancing\", \"Biking\"]\n",
    "final_grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's group data in this `DataFrame` by hobby:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_grades = final_grades.groupby(\"hobby\")\n",
    "for key, item in grouped_grades:\n",
    "    print(grouped_grades.get_group(key), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to compute the average grade per hobby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_grades.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was easy! Note that the `NaN` values have simply been skipped when computing the means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` can save `DataFrame`s to various backends, including file formats such as CSV, Excel, JSON, HTML and HDF5, or to a SQL database. Let's create a `DataFrame` to demonstrate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(\n",
    "    [[\"Biking\", 68.5, 1985, np.nan], [\"Dancing\", 83.1, 1984, 3]], \n",
    "    columns=[\"hobby\",\"weight\",\"birthyear\",\"children\"],\n",
    "    index=[\"alice\", \"bob\"]\n",
    ")\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: rgb(255,165,0); border: solid 1px rgb(129,199,132); padding: 10px;\">    \n",
    "\n",
    "<h2>Plotting a DataFrame</h2>\n",
    "    \n",
    "</div>\n",
    "\n",
    "Just like for `Series`, `pandas` makes it easy to draw nice graphs based on a `DataFrame`.\n",
    "\n",
    "For example, it is easy to create a bar plot from a `DataFrame`'s data by calling its `plot` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people.plot(kind = \"bar\", y = [\"body_mass_index\"])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass extra arguments supported by matplotlib's functions. For example, we can create scatterplot and pass it a list of sizes using the `s` argument of matplotlib's `scatter()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "people.plot(kind = \"scatter\", x = \"height\", y = \"weight\", s=[40, 120, 200])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, there are way too many options to list here: the best option is to scroll through the [Visualization](http://pandas.pydata.org/pandas-docs/stable/visualization.html) page in `pandas` documentation and find the plot you are interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: rgb(255,165,0); border: solid 1px rgb(129,199,132); padding: 10px;\">    \n",
    "\n",
    "<h2>Combining DataFrames</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL-like joins\n",
    "One powerful feature of `pandas` is it's ability to perform SQL-like joins on `DataFrame`s. Various types of joins are supported: inner joins, left/right outer joins and full joins. To illustrate this, let's start by creating a couple simple `DataFrame`s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_loc = pd.DataFrame(\n",
    "    [\n",
    "        [\"CA\", \"San Francisco\", 37.781334, -122.416728],\n",
    "        [\"NY\", \"New York\", 40.705649, -74.008344],\n",
    "        [\"FL\", \"Miami\", 25.791100, -80.320733],\n",
    "        [\"OH\", \"Cleveland\", 41.473508, -81.739791],\n",
    "        [\"UT\", \"Salt Lake City\", 40.755851, -111.896657]\n",
    "    ], columns=[\"state\", \"city\", \"lat\", \"lng\"])\n",
    "city_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_pop = pd.DataFrame(\n",
    "    [\n",
    "        [808976, \"San Francisco\", \"California\"],\n",
    "        [8363710, \"New York\", \"New-York\"],\n",
    "        [413201, \"Miami\", \"Florida\"],\n",
    "        [2242193, \"Houston\", \"Texas\"]\n",
    "    ], index=[3,4,5,6], columns=[\"population\", \"city\", \"state\"])\n",
    "city_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's join these `DataFrame`s using the `merge()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left=city_loc, right=city_pop, on=\"city\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that both `DataFrame`s have a column named `state`, so in the result they got renamed to `state_x` and `state_y`.\n",
    "\n",
    "Also, note that Cleveland, Salt Lake City and Houston were dropped because they don't exist in *both* `DataFrame`s. This is the equivalent of a SQL `INNER JOIN`. If you want a `FULL OUTER JOIN`, where no city gets dropped and `NaN` values are added, you must specify `how=\"outer\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cities = pd.merge(left=city_loc, right=city_pop, on=\"city\", how=\"outer\")\n",
    "all_cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course `LEFT OUTER JOIN` is also available by setting `how=\"left\"`: only the cities present in the left `DataFrame` end up in the result. Similarly, with `how=\"right\"` only cities in the right `DataFrame` appear in the result. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left=city_loc, right=city_pop, on=\"city\", how=\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the key to join on is actually in one (or both) `DataFrame`'s index, you must use `left_index=True` and/or `right_index=True`. If the key column names differ, you must use `left_on` and `right_on`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_pop2 = city_pop.copy()\n",
    "city_pop2.columns = [\"population\", \"name\", \"state\"]\n",
    "pd.merge(left=city_loc, right=city_pop2, left_on=\"city\", right_on=\"name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Concatenation</h2>\n",
    "\n",
    "</div>\n",
    "Rather than joining `DataFrame`s, we may just want to concatenate them using `concat()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_concat = pd.concat([city_loc, city_pop], sort = False)\n",
    "result_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this operation aligned the data horizontally (by columns) but not vertically (by rows). In this example, we end up with multiple rows having the same index (eg. 3). `pandas` handles this rather gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_concat.loc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can tell `pandas` to just ignore the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([city_loc, city_pop], ignore_index=True, sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when a column does not exist in a `DataFrame`, it acts as if it was filled with `NaN` values. If we set `join=\"inner\"`, then only columns that exist in *both* `DataFrame`s are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([city_loc, city_pop], join=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can concatenate `DataFrame`s horizontally instead of vertically by setting `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat([city_loc, city_pop], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case it really does not make much sense because the indices do not align well (eg. Cleveland and San Francisco end up on the same row, because they shared the index label `3`). So let's reindex the `DataFrame`s by city name before concatenating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.concat([city_loc.set_index(\"city\"), city_pop.set_index(\"city\")], axis=1, sort = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks a lot like a `FULL OUTER JOIN`, except that the `state` columns were not renamed to `state_x` and `state_y`, and the `city` column is now the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(27,94,32); background: rgb(200,230,201); border: solid 1px rgb(129,199,132); padding: 10px;\">\n",
    "\n",
    "<h3>Challenge:</h3>\n",
    "\n",
    "Add another person as a new row to the previous DataFrame `employees_df` with the following values (**HINT**: use `pd.concat`):\n",
    "\n",
    "name: `mike`, age: `0`, state: `new york`, num_children: `1`, num_pets: `0`.\n",
    "\n",
    "Since this new person has a child, his age cannot be zero. Replace it with the median age of all other people in the DataFrame.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: rgb(255,165,0); border: solid 1px rgb(129,199,132); padding: 10px;\">    \n",
    "\n",
    "<h2>Section 2: Exploring a Real Dataset</h2>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will work with the Breast Cancer Wisconsin (Diagnostic) dataset from the [UCI data repository](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic). We are using a copy of the dataset with some added error that we will look for.\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at http://www.cs.wisc.edu/~street/images/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Loading data from CSV</h2>\n",
    "\n",
    "</div>\n",
    "\n",
    "Pandas allows us to read in tables from file types such as csv, json, html and excel. \n",
    "\n",
    "Here we will load the \"Wisconsin Diagnostic Breast Cancer (WDBC)\" dataset from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First let's check that we are in the \"workshop\" dir.\n",
    "os.getcwd()\n",
    "# Now look inside the \"data\" dir for the file \"wdbc.data.csv\"\n",
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the csv into a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wdbc_df = pd.read_csv(\"data/wdbc.data.csv\")\n",
    "wdbc_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas reads the first line as a header by default. Let's try again with `header=None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wdbc_df = pd.read_csv(\"data/wdbc.data.csv\", header=None)\n",
    "wdbc_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(27,94,32); background: rgb(200,230,201); border: solid 1px rgb(129,199,132); padding: 10px;\">\n",
    "\n",
    "<h3>Challenge:</h3>\n",
    "\n",
    "Using the list of column names below, add column labels to the dataframe.\n",
    "    \n",
    "Hint: View the columns attribute.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Column labels\n",
    "col_names = ['ID', 'Diagnosis', 'radius1', 'texture1', 'perimeter1', 'area1', 'smoothness1', 'compactness1', 'concavity1', 'concave_points1', 'symmetry1', 'fractal_dimension1', 'radius2', 'texture2', 'perimeter2', 'area2', 'smoothness2', 'compactness2', 'concavity2', 'concave_points2', 'symmetry2', 'fractal_dimension2', 'radius3', 'texture3', 'perimeter3', 'area3', 'smoothness3', 'compactness3', 'concavity3', 'concave_points3', 'symmetry3', 'fractal_dimension3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add column labels\n",
    "# Your solution here\n",
    "\n",
    "# View dataframe\n",
    "wdbc_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: rgb(255,165,0); border: solid 1px rgb(129,199,132); padding: 10px;\">    \n",
    "\n",
    "<h2>Exploring your data</h2>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(0,0,0); background: #0096FF; border: solid 1px rgb(0,0,0); padding: 10px;\">\n",
    "\n",
    "<h2>Overview functions</h2>\n",
    "\n",
    "</div>\n",
    "\n",
    "When dealing with large `DataFrames`, it is useful to get a quick overview of its content. `pandas` offers a few functions for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape attribute will give use the dimensions of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wdbc_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `head()` method returns the top 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdbc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course there's also a `tail()` function to view the bottom 5 rows. You can pass the number of rows you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdbc_df.tail(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `info()` method prints out a summary of each columns contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdbc_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the `describe()` method gives a nice overview of the main aggregated values over each column:\n",
    "* `count`: number of non-null (not NaN) values\n",
    "* `mean`: mean of non-null values\n",
    "* `std`: [standard deviation](https://en.wikipedia.org/wiki/Standard_deviation) of non-null values\n",
    "* `min`: minimum of non-null values\n",
    "* `25%`, `50%`, `75%`: 25th, 50th and 75th [percentile](https://en.wikipedia.org/wiki/Percentile) of non-null values\n",
    "* `max`: maximum of non-null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "wdbc_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: rgb(255,165,0); border: solid 1px rgb(129,199,132); padding: 10px;\">    \n",
    "\n",
    "<h2>Data Cleaning</h2>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find missing values with `.isnull()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wdbc_df.isnull()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(27,94,32); background: rgb(200,230,201); border: solid 1px rgb(129,199,132); padding: 10px;\">\n",
    "\n",
    "<h3>Challenge:</h3>\n",
    "\n",
    "This is difficult to read, let's try chaining the previous command together with `.sum()`\n",
    "\n",
    "Hint: Try passing the arg `axis=1` to the `sum` method. How does this change the result?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chain with the .sum() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove rows with missing values using `.dropna()`**\n",
    "\n",
    "`.dropna()` returns a new dataframe without editing the original.\n",
    "\n",
    "To edit the original use `wdbc_df.dropna(inplace = True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_wdbc_df = wdbc_df.dropna()\n",
    "\n",
    "wdbc_df.shape\n",
    "new_wdbc_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace Empty Values wit `fillna()`**\n",
    "\n",
    "Another way of dealing with empty cells is to insert a new value instead.\n",
    "\n",
    "This way you do not have to delete entire rows just because of some empty cells.\n",
    "\n",
    "The `fillna()` method allows us to replace empty cells with a value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nan_to_zero = wdbc_df.fillna(0)\n",
    "wdbc_df.head(3)\n",
    "nan_to_zero.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replace Only For Specified Columns**\n",
    "\n",
    "The example above replaces all empty cells in the whole Data Frame.\n",
    "\n",
    "To only replace empty values for one column, specify the column name for the DataFrame.\n",
    "\n",
    "Here we will replace null values in the \"texture1\" column with the mean value for that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = wdbc_df[\"texture1\"].mean()\n",
    "\n",
    "wdbc_df[\"texture1\"].fillna(x, inplace = True)\n",
    "\n",
    "wdbc_df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(new_wdbc_df.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_wdbc_df.shape\n",
    "\n",
    "new_wdbc_df.drop_duplicates(inplace = True)\n",
    "\n",
    "new_wdbc_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: rgb(255,165,0); border: solid 1px rgb(129,199,132); padding: 10px;\">    \n",
    "\n",
    "<h2>Saving to files</h2>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's save our cleaned dataframe to CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_wdbc_df.to_csv(\"data/cleaned_wdbc.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: rgb(255,165,0); border: solid 1px rgb(129,199,132); padding: 10px;\">    \n",
    "\n",
    "<h2>Query by group</h2>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(27,94,32); background: rgb(200,230,201); border: solid 1px rgb(129,199,132); padding: 10px;\">\n",
    "\n",
    "<h3>Challenge:</h3>\n",
    "\n",
    "Using `.groupby` find the mean radius of tumors in the benign and malignant groups.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: rgb(255,165,0); border: solid 1px rgb(129,199,132); padding: 10px;\">    \n",
    "\n",
    "<h2>Plotting data</h2>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example scatterplot comparing two variables coloured by category.\n",
    "\n",
    "See if you can find a highly correlated pair of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "var1 = 'radius1'\n",
    "var2 = 'texture1'\n",
    "\n",
    "# Calculate linear regression\n",
    "slope, intercept, r_value, p_value, std_err = linregress(new_wdbc_df[var1], new_wdbc_df[var2])\n",
    "\n",
    "# Calculate R-squared\n",
    "r_squared = r_value**2\n",
    "\n",
    "# Create scatterplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=new_wdbc_df, x=var1, y=var2, hue='Diagnosis', palette='Set1')\n",
    "\n",
    "# Add R-squared to the plot\n",
    "plt.text(\n",
    "    x=new_wdbc_df[var1].min(), \n",
    "    y=new_wdbc_df[var2].max(), \n",
    "    s=f\"$R^2$: {r_squared:.2f}\", \n",
    "    fontsize=12,\n",
    "    verticalalignment='top',\n",
    "    bbox=dict(facecolor='white', alpha=0.5)\n",
    ")\n",
    "\n",
    "# Plot title and labels\n",
    "plt.title('Scatterplot of Radius vs Texture by Diagnosis with R-squared')\n",
    "plt.xlabel(var1)\n",
    "plt.ylabel(var2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example hitogram for a single variable grouped by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_var = 'radius1'\n",
    "\n",
    "# Plot histograms by category\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=new_wdbc_df, x=x_var, hue='Diagnosis', multiple='stack', kde=True, palette='Set1', bins=10)\n",
    "\n",
    "# Plot title and labels\n",
    "plt.title(f\"Histogram of {x_var} by Diagnosis Category\")\n",
    "plt.xlabel(x_var)\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Machine Learning Notebooks](https://github.com/ageron/handson-ml2/blob/master/tools_pandas.ipynb)\n",
    "* [Python for Data Analysis](https://www.oreilly.com/library/view/python-for-data/9781491957653/)\n",
    "* [Rebecca Barter Blog - From R to Python](https://rebeccabarter.com/blog/2023-09-11-from_r_to_python)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_section_display": "none",
   "toc_threshold": 6,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
